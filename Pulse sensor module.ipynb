{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing and feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HR</th>\n",
       "      <th>Attentive</th>\n",
       "      <th>dropValue</th>\n",
       "      <th>rollmean</th>\n",
       "      <th>rollmedian</th>\n",
       "      <th>rollstd</th>\n",
       "      <th>rollMax</th>\n",
       "      <th>rollMin</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-01-09 13:00:57</th>\n",
       "      <td>81.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3.0</td>\n",
       "      <td>79.500000</td>\n",
       "      <td>79.5</td>\n",
       "      <td>2.121320</td>\n",
       "      <td>81.0</td>\n",
       "      <td>78.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-09 13:00:58</th>\n",
       "      <td>84.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3.0</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>81.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>84.0</td>\n",
       "      <td>78.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-09 13:00:59</th>\n",
       "      <td>90.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>6.0</td>\n",
       "      <td>83.250000</td>\n",
       "      <td>82.5</td>\n",
       "      <td>5.123475</td>\n",
       "      <td>90.0</td>\n",
       "      <td>78.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-09 13:01:00</th>\n",
       "      <td>90.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.0</td>\n",
       "      <td>84.600000</td>\n",
       "      <td>84.0</td>\n",
       "      <td>5.366563</td>\n",
       "      <td>90.0</td>\n",
       "      <td>78.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-09 13:01:01</th>\n",
       "      <td>92.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2.0</td>\n",
       "      <td>85.833333</td>\n",
       "      <td>87.0</td>\n",
       "      <td>5.671567</td>\n",
       "      <td>92.0</td>\n",
       "      <td>78.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-09 20:03:05</th>\n",
       "      <td>80.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3.0</td>\n",
       "      <td>82.983333</td>\n",
       "      <td>81.0</td>\n",
       "      <td>6.347271</td>\n",
       "      <td>94.0</td>\n",
       "      <td>74.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-09 20:03:06</th>\n",
       "      <td>87.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>7.0</td>\n",
       "      <td>82.950000</td>\n",
       "      <td>81.0</td>\n",
       "      <td>6.320333</td>\n",
       "      <td>94.0</td>\n",
       "      <td>74.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-09 20:03:07</th>\n",
       "      <td>86.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>82.916667</td>\n",
       "      <td>81.0</td>\n",
       "      <td>6.298484</td>\n",
       "      <td>94.0</td>\n",
       "      <td>74.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-09 20:03:08</th>\n",
       "      <td>86.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.0</td>\n",
       "      <td>82.900000</td>\n",
       "      <td>81.0</td>\n",
       "      <td>6.288812</td>\n",
       "      <td>94.0</td>\n",
       "      <td>74.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-09 20:03:09</th>\n",
       "      <td>85.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>82.866667</td>\n",
       "      <td>81.0</td>\n",
       "      <td>6.271990</td>\n",
       "      <td>94.0</td>\n",
       "      <td>74.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>54701 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       HR Attentive  dropValue   rollmean  rollmedian  \\\n",
       "Time                                                                    \n",
       "2022-01-09 13:00:57  81.0       Yes        3.0  79.500000        79.5   \n",
       "2022-01-09 13:00:58  84.0       Yes        3.0  81.000000        81.0   \n",
       "2022-01-09 13:00:59  90.0       Yes        6.0  83.250000        82.5   \n",
       "2022-01-09 13:01:00  90.0       Yes        0.0  84.600000        84.0   \n",
       "2022-01-09 13:01:01  92.0       Yes        2.0  85.833333        87.0   \n",
       "...                   ...       ...        ...        ...         ...   \n",
       "2022-01-09 20:03:05  80.0       Yes        3.0  82.983333        81.0   \n",
       "2022-01-09 20:03:06  87.0       Yes        7.0  82.950000        81.0   \n",
       "2022-01-09 20:03:07  86.0       Yes       -1.0  82.916667        81.0   \n",
       "2022-01-09 20:03:08  86.0       Yes        0.0  82.900000        81.0   \n",
       "2022-01-09 20:03:09  85.0       Yes       -1.0  82.866667        81.0   \n",
       "\n",
       "                      rollstd  rollMax  rollMin  \n",
       "Time                                             \n",
       "2022-01-09 13:00:57  2.121320     81.0     78.0  \n",
       "2022-01-09 13:00:58  3.000000     84.0     78.0  \n",
       "2022-01-09 13:00:59  5.123475     90.0     78.0  \n",
       "2022-01-09 13:01:00  5.366563     90.0     78.0  \n",
       "2022-01-09 13:01:01  5.671567     92.0     78.0  \n",
       "...                       ...      ...      ...  \n",
       "2022-01-09 20:03:05  6.347271     94.0     74.0  \n",
       "2022-01-09 20:03:06  6.320333     94.0     74.0  \n",
       "2022-01-09 20:03:07  6.298484     94.0     74.0  \n",
       "2022-01-09 20:03:08  6.288812     94.0     74.0  \n",
       "2022-01-09 20:03:09  6.271990     94.0     74.0  \n",
       "\n",
       "[54701 rows x 8 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import pickle\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score,classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "def preprocessing(i, j):\n",
    "    dataframes_list = []\n",
    "    for i in range(i, j+1):\n",
    "        #Preprocessing\n",
    "        from dateutil.parser import parse\n",
    "    \n",
    "        # Import as Dataframe\n",
    "        dataset = pd.read_csv(\"S\"+str(i)+\".csv\")\n",
    "\n",
    "        # get the number of missing data points per column\n",
    "        missing_values_count = dataset.isnull().sum()\n",
    "\n",
    "        #Remove rows with missing values\n",
    "        dataset = dataset.dropna()\n",
    "\n",
    "        dataset['Time'] = pd.to_datetime(dataset['Time'], infer_datetime_format = True)\n",
    "        indexed_dataset = dataset.set_index(['Time'])\n",
    "\n",
    "        y = indexed_dataset['HR']\n",
    "\n",
    "        #identify data that are not considered as outliers\n",
    "        #removed_outliers = y.between(y.quantile(.02), y.quantile(.99))\n",
    "\n",
    "        #identify outliers\n",
    "        #index_names = indexed_dataset[~removed_outliers].index # INVERT removed_outliers!!\n",
    "        #print(index_names) # The resulting dates to drop.\n",
    "\n",
    "        #Remove outliers\n",
    "        #indexed_dataset.drop(index_names, inplace=True)\n",
    "\n",
    "        #Feature Extraction\n",
    "        #Rolling features were used because it is a widely used method for time series data to smooth out short-term fluctuations \n",
    "        #and highlight trends in between a considered time period. \n",
    "\n",
    "        indexed_dataset['dropValue'] = indexed_dataset['HR'].diff()\n",
    "        indexed_dataset['rollmean'] = indexed_dataset['HR'].rolling(window = 60, min_periods=1).mean()\n",
    "        indexed_dataset['rollmedian'] = indexed_dataset['HR'].rolling(window = 60, min_periods=1).median()\n",
    "        indexed_dataset['rollstd'] = indexed_dataset['HR'].rolling(window = 60, min_periods=1).std()\n",
    "        indexed_dataset['rollMax'] = indexed_dataset['HR'].rolling(window = 60, min_periods=1).max()\n",
    "        indexed_dataset['rollMin'] = indexed_dataset['HR'].rolling(window = 60, min_periods=1).min()\n",
    "\n",
    "        indexed_dataset = indexed_dataset.dropna()\n",
    "        indexed_dataset.to_csv(\"SNew\"+str(i)+\".csv\", index = True)\n",
    "        \n",
    "\n",
    "        dataframes_list.append(indexed_dataset)\n",
    "            \n",
    "    return dataframes_list \n",
    "\n",
    "training_dataset = pd.concat(preprocessing(1, 15))\n",
    "training_dataset.to_csv(\"TrainingData_processed.csv\", index = True)\n",
    "\n",
    "test_dataset = pd.concat(preprocessing(16, 18))\n",
    "test_dataset.to_csv(\"TestData_processed.csv\", index = True)\n",
    "\n",
    "training_dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Feature        Score\n",
      "4     rollstd  4274.731703\n",
      "5     rollMax  3697.342199\n",
      "0          HR  3001.693564\n",
      "2    rollmean  1371.309387\n",
      "3  rollmedian  1027.111558\n",
      "6     rollMin   932.452301\n",
      "1   dropValue    13.848855\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "\n",
    "X = training_dataset.iloc[:, [0, 2, 3, 4, 5, 6, 7]].values\n",
    "y = training_dataset.iloc[:, 1].values\n",
    "\n",
    "X_train = X\n",
    "y_train = y\n",
    "\n",
    "X_test = test_dataset.iloc[:, [0, 2, 3, 4, 5, 6, 7]].values\n",
    "y_test = test_dataset.iloc[:, 1].values\n",
    "\n",
    "#apply SelectKBest class to extract top 10 best features\n",
    "bestfeatures = SelectKBest(score_func=f_classif, k=7)\n",
    "fit = bestfeatures.fit(X,y)\n",
    "dfscores = pd.DataFrame(fit.scores_)\n",
    "index = ['HR', 'dropValue', 'rollmean', 'rollmedian', 'rollstd', 'rollMax', 'rollMin']\n",
    "dfcolumns = pd.DataFrame(index)\n",
    "\n",
    "#concat two dataframes for better visualization \n",
    "featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
    "featureScores.columns = ['Feature','Score']  #naming the dataframe columns\n",
    "print(featureScores.nlargest(7,'Score'))  #print 10 best features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = training_dataset.iloc[:, [0, 2, 3, 4, 5, 6, 7]].values\n",
    "y = training_dataset.iloc[:, 1].values\n",
    "\n",
    "X_train = X\n",
    "y_train = y\n",
    "\n",
    "X_test = test_dataset.iloc[:, [0, 2, 3, 4, 5, 6, 7]].values\n",
    "y_test = test_dataset.iloc[:, 1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mlxtend\n",
      "  Downloading mlxtend-0.19.0-py2.py3-none-any.whl (1.3 MB)\n",
      "Requirement already satisfied: scikit-learn>=0.20.3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from mlxtend) (0.23.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\hp\\anaconda3\\lib\\site-packages (from mlxtend) (50.3.1.post20201107)\n",
      "Requirement already satisfied: numpy>=1.16.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from mlxtend) (1.19.2)\n",
      "Requirement already satisfied: pandas>=0.24.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from mlxtend) (1.1.3)\n",
      "Requirement already satisfied: matplotlib>=3.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from mlxtend) (3.3.2)\n",
      "Requirement already satisfied: scipy>=1.2.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from mlxtend) (1.5.2)\n",
      "Requirement already satisfied: joblib>=0.13.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from mlxtend) (0.17.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from scikit-learn>=0.20.3->mlxtend) (2.1.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pandas>=0.24.2->mlxtend) (2020.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pandas>=0.24.2->mlxtend) (2.8.1)\n",
      "Requirement already satisfied: certifi>=2020.06.20 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (2020.6.20)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (0.10.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (8.0.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7.3->pandas>=0.24.2->mlxtend) (1.15.0)\n",
      "Installing collected packages: mlxtend\n",
      "Successfully installed mlxtend-0.19.0\n"
     ]
    }
   ],
   "source": [
    "!pip install mlxtend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 265    0 1653]\n",
      " [   4   52   57]\n",
      " [ 311   28 8780]]\n",
      "\n",
      "0.8158744394618834\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "            No       0.46      0.14      0.21      1918\n",
      "Not Applicable       0.65      0.46      0.54       113\n",
      "           Yes       0.84      0.96      0.90      9119\n",
      "\n",
      "      accuracy                           0.82     11150\n",
      "     macro avg       0.65      0.52      0.55     11150\n",
      "  weighted avg       0.77      0.82      0.77     11150\n",
      "\n",
      "['Yes' 'Yes' 'Yes' ... 'Yes' 'Yes' 'Yes']\n"
     ]
    }
   ],
   "source": [
    "# Random forest classifier\n",
    "import mlxtend \n",
    "from mlxtend.evaluate import bias_variance_decomp\n",
    "rf = RandomForestClassifier(n_estimators = 40)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "print()\n",
    "print(accuracy_score(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0 1918]\n",
      " [   6    1  106]\n",
      " [   0    5 9114]]\n",
      "\n",
      "0.8174887892376682\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "            No       0.00      0.00      0.00      1918\n",
      "Not Applicable       0.17      0.01      0.02       113\n",
      "           Yes       0.82      1.00      0.90      9119\n",
      "\n",
      "      accuracy                           0.82     11150\n",
      "     macro avg       0.33      0.34      0.31     11150\n",
      "  weighted avg       0.67      0.82      0.74     11150\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(solver='liblinear')\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "print()\n",
    "print(accuracy_score(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 331    0 1587]\n",
      " [  13   53   47]\n",
      " [ 611   48 8460]]\n",
      "\n",
      "0.7931838565022421\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "            No       0.35      0.17      0.23      1918\n",
      "Not Applicable       0.52      0.47      0.50       113\n",
      "           Yes       0.84      0.93      0.88      9119\n",
      "\n",
      "      accuracy                           0.79     11150\n",
      "     macro avg       0.57      0.52      0.54     11150\n",
      "  weighted avg       0.75      0.79      0.76     11150\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "print()\n",
    "print(accuracy_score(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0 1918]\n",
      " [   0   59   54]\n",
      " [   0   27 9092]]\n",
      "\n",
      "0.8207174887892377\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "            No       0.00      0.00      0.00      1918\n",
      "Not Applicable       0.69      0.52      0.59       113\n",
      "           Yes       0.82      1.00      0.90      9119\n",
      "\n",
      "      accuracy                           0.82     11150\n",
      "     macro avg       0.50      0.51      0.50     11150\n",
      "  weighted avg       0.68      0.82      0.74     11150\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "SVC = SVC(kernel = 'rbf')\n",
    "SVC.fit(X_train, y_train)\n",
    "\n",
    "y_pred = SVC.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "print()\n",
    "print(accuracy_score(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write the model into a pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.83\n",
      "0.0\n",
      "0.83\n",
      "5.0\n",
      "14.17\n",
      "0.0\n",
      "0.83\n",
      "0.0\n",
      "0.0\n",
      "5.83\n",
      "1.67\n",
      "0.0\n",
      "0.0\n",
      "7.5\n",
      "7.5\n",
      "0.0\n",
      "0.0\n",
      "10.83\n",
      "9.17\n",
      "22.5\n",
      "0.0\n",
      "10.0\n",
      "3.33\n",
      "12.5\n",
      "10.0\n",
      "15.83\n",
      "4.17\n",
      "8.33\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.83\n",
      "0.0\n",
      "0.0\n",
      "4.17\n",
      "0.0\n",
      "6.67\n",
      "20.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "7.5\n",
      "0.0\n",
      "1.67\n",
      "22.5\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "3.33\n",
      "1.67\n",
      "0.83\n",
      "19.17\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "5.83\n",
      "0.0\n",
      "0.0\n",
      "5.0\n",
      "0.0\n",
      "0.0\n",
      "19.17\n",
      "5.83\n",
      "7.5\n",
      "9.17\n",
      "20.83\n",
      "23.33\n",
      "0.0\n",
      "6.67\n",
      "14.17\n",
      "6.67\n",
      "1.67\n",
      "0.0\n",
      "5.83\n",
      "10.0\n",
      "12.5\n",
      "0.83\n",
      "1.67\n",
      "9.17\n",
      "9.17\n",
      "4.17\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.67\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.83\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "with open('DrowsyRate_pulseModule.pkl', 'wb') as handle:\n",
    "    training_dataset = pd.read_csv('TrainingData_processed.csv')\n",
    "    \n",
    "    training_dataset['Time'] = pd.to_datetime(training_dataset['Time'], infer_datetime_format = True)\n",
    "    training_dataset = training_dataset.set_index(['Time'])\n",
    "\n",
    "    test_dataset = pd.read_csv('TestData_processed.csv')\n",
    "    test_dataset['Time'] = pd.to_datetime(test_dataset['Time'], infer_datetime_format = True)\n",
    "    test_dataset = test_dataset.set_index(['Time'])\n",
    "\n",
    "    \n",
    "    X = training_dataset.iloc[:, [0, 2, 3, 4, 5, 6, 7]].values\n",
    "    y = training_dataset.iloc[:, 1].values\n",
    "\n",
    "    X_train = X\n",
    "    y_train = y\n",
    "\n",
    "    X_test = test_dataset.iloc[:, [0, 2, 3, 4, 5, 6, 7]].values\n",
    "    y_test = test_dataset.iloc[:, 1].values\n",
    "\n",
    "   # Random forest classifier\n",
    "\n",
    "    rf = RandomForestClassifier(random_state = 40)\n",
    "    rf.fit(X_train, y_train)  \n",
    "    \n",
    "    y_pred = rf.predict(X_test)\n",
    "    # Predicted drowsiness as a percentage for every 2 minutes\n",
    "    DrowsyPercentageList = []\n",
    "    for i in range(1, len(y_pred), 120):\n",
    "        sum_drowsy = 0\n",
    "        sum_not_drowsy = 0\n",
    "        sum_not_applicable = 0\n",
    "        if(len(y_pred) - i >=119):\n",
    "            for j in range(i, i+120, 1):\n",
    "                if(y_pred[j-1] == \"Yes\"):\n",
    "                    sum_not_drowsy = sum_not_drowsy + 1\n",
    "                elif(y_pred[j-1] == \"Not Applicable\"):\n",
    "                    sum_not_applicable = sum_not_applicable + 1    \n",
    "                else:\n",
    "                    sum_drowsy = sum_drowsy + 1\n",
    "            Total = sum_drowsy + sum_not_drowsy + sum_not_applicable\n",
    "            DrowsyPercentage = (sum_drowsy/Total)*100\n",
    "            DrowsyPercentageList.append(round(DrowsyPercentage, 2))\n",
    "            print(round(DrowsyPercentage, 2))\n",
    "            \n",
    "            \n",
    "    pickle.dump( DrowsyPercentageList, handle)       \n",
    "    #pickle.dump(b, handle)\n",
    "    #handle.close()\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.83, 0.0, 0.83, 5.0, 14.17, 0.0, 0.83, 0.0, 0.0, 5.83, 1.67, 0.0, 0.0, 7.5, 7.5, 0.0, 0.0, 10.83, 9.17, 22.5, 0.0, 10.0, 3.33, 12.5, 10.0, 15.83, 4.17, 8.33, 0.0, 0.0, 0.0, 0.83, 0.0, 0.0, 4.17, 0.0, 6.67, 20.0, 0.0, 0.0, 0.0, 0.0, 7.5, 0.0, 1.67, 22.5, 0.0, 0.0, 0.0, 3.33, 1.67, 0.83, 19.17, 0.0, 0.0, 0.0, 5.83, 0.0, 0.0, 5.0, 0.0, 0.0, 19.17, 5.83, 7.5, 9.17, 20.83, 23.33, 0.0, 6.67, 14.17, 6.67, 1.67, 0.0, 5.83, 10.0, 12.5, 0.83, 1.67, 9.17, 9.17, 4.17, 0.0, 0.0, 0.0, 1.67, 0.0, 0.0, 0.0, 0.83, 0.0]\n"
     ]
    }
   ],
   "source": [
    "with open('DrowsyRate_pulseModule.pkl', 'rb') as handle:\n",
    "    b = pickle.load(handle)\n",
    "print (b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
